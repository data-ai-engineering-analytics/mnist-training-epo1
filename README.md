# MNIST CNN Training Project

A PyTorch-based Convolutional Neural Network implementation for MNIST digit classification with comprehensive training reports and evaluation metrics.

## ğŸ—ï¸ Model Architecture

The optimized CNN model consists of 4 convolutional layers followed by 1 fully connected layer:

```
Input (1, 28, 28) 
    â†“
Conv2d(1â†’8, kernel=3) + ReLU + MaxPool2d(2)
    â†“
Conv2d(8â†’16, kernel=3) + ReLU + MaxPool2d(2)
    â†“
Conv2d(16â†’22, kernel=3) + ReLU
    â†“
Conv2d(22â†’56, kernel=3) + ReLU + MaxPool2d(2)
    â†“
Flatten â†’ Linear(56Ã—4Ã—4 â†’ 10) + LogSoftmax
    â†“
Output (10 classes)
```

### Architecture Details:
- **Total Parameters**: 24,552
- **Trainable Parameters**: 24,552
- **Input Size**: 28Ã—28 grayscale images
- **Output**: 10 classes (digits 0-9)
- **Activation**: ReLU for hidden layers, LogSoftmax for output
- **Key Optimization**: Removed the second fully connected layer to reduce parameters while maintaining performance

## ğŸš€ Quick Start

### Prerequisites
- Python â‰¥ 3.12
- UV package manager

### Installation
```bash
# Clone the repository
git clone <repository-url>
cd mnist-training-epo1

# Install dependencies using UV
uv sync

# Activate virtual environment
source .venv/bin/activate
```

### Training
```bash
# Run the training notebook
jupyter notebook mnist_cnn_training.ipynb
```

## ğŸ“Š Training Configuration

| Parameter | Value |
|-----------|-------|
| **Dataset** | MNIST |
| **Batch Size** | 512 |
| **Epochs** | 20 |
| **Optimizer** | SGD (lr=0.001, momentum=0.9) |
| **Scheduler** | StepLR (step_size=15, gamma=0.1) |
| **Loss Function** | CrossEntropyLoss |
| **Device** | MPS (Apple Silicon) / CUDA / CPU |

## ğŸ“ˆ Training Reports

Comprehensive HTML reports are automatically generated for each training run:

### Latest Training Reports:
- [CNN Model_MNIST_20250919_162301.html](reports/CNN%20Model_MNIST_20250919_162301.html) - **95.21% Accuracy** (24,552 parameters)
- [CNN Model_MNIST_20250919_151823.html](reports/CNN%20Model_MNIST_20250919_151823.html) - 95.07% Accuracy
- [CNN Model_MNIST_20250919_130247.html](reports/CNN%20Model_MNIST_20250919_130247.html)
- [CNN Model_MNIST_20250919_125504.html](reports/CNN%20Model_MNIST_20250919_125504.html)

### Report Features:
- ğŸ“Š **Training Metrics**: Loss and accuracy curves
- ğŸ”§ **Model Configuration**: Architecture and hyperparameters
- ğŸ“ˆ **Epoch-by-Epoch Results**: Detailed training history
- ğŸ¯ **Final Performance**: Test accuracy and loss
- ğŸ“± **Responsive Design**: Mobile-friendly HTML reports

## ğŸ¯ Performance Metrics

### Latest Results:
- **Final Test Accuracy**: 95.21%
- **Final Test Loss**: 0.1559
- **Training Epochs**: 1 (single epoch run)
- **Model Parameters**: 24,552

> **Achievement**: Successfully achieved >95% accuracy with <25,000 parameters in a single epoch through careful architecture optimization and hyperparameter tuning.

## ğŸ“Š Incremental Optimization Journey

The following table shows the step-by-step improvements made to achieve >95% test accuracy with <25,000 parameters:

| Commit | Change Description | Batch Size | Test Accuracy | Parameters | Key Insight |
|--------|-------------------|------------|---------------|------------|-------------|
| `4e218cb` | Reduced batch size from 512 to 256 | 256 | 76.74% | ~593K | Smaller batch sizes improve learning |
| `a27c374` | Further reduced batch size to 128 | 128 | 87.48% | ~593K | Continued batch size optimization |
| `68d1bb1` | Reduced batch size to 64 | 64 | 91.83% | ~593K | Significant accuracy improvement |
| `3ae9ac8` | Reduced batch size to 32 | 32 | 94.40% | ~593K | Approaching target accuracy |
| `72452f7` | Reduced batch size to 16 | 16 | 94.79% | ~593K | Peak accuracy with original architecture |
| `0ccde0f` | Increased batch size to 32, changed layer channels | 32 | 92.36% | ~593K | Architecture changes needed |
| `b224f37` | **Optimized architecture**: Changed I/O channels and removed last FC layer | 32 | **95.07%** | **24,552** | **Target achieved!** |
| `fb087de` | Added shuffle=True for better results | 32 | **95.21%** | **24,552** | Final optimization |

### Key Optimizations Applied:
1. **Batch Size Tuning**: Systematically reduced from 512 â†’ 32 for optimal learning
2. **Architecture Optimization**: 
   - Reduced channel counts: 1â†’8â†’16â†’22â†’56 (vs original 1â†’32â†’64â†’128â†’256)
   - Removed second fully connected layer (FC2)
   - Direct connection from FC1 to output layer
3. **Parameter Reduction**: From 593,200 â†’ 24,552 parameters (96% reduction)
4. **Data Shuffling**: Enabled shuffle=True for better generalization

## ğŸ§  Model Architecture Details

### Net() Model Output
```
Net(
  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1))
  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))
  (conv3): Conv2d(16, 22, kernel_size=(3, 3), stride=(1, 1))
  (conv4): Conv2d(22, 56, kernel_size=(3, 3), stride=(1, 1))
  (fc1): Linear(in_features=896, out_features=10, bias=True)
)
```

### Model Summary (torchsummary)
```
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
â”œâ”€Conv2d: 1-1                            80
â”œâ”€Conv2d: 1-2                            1,168
â”œâ”€Conv2d: 1-3                            3,190
â”œâ”€Conv2d: 1-4                            11,144
â”œâ”€Linear: 1-5                            8,970
=================================================================
Total params: 24,552
Trainable params: 24,552
Non-trainable params: 0
=================================================================
```

## ğŸ“Š Training Results

### Training and Test Accuracy Output
```
Epoch 1
Train: Loss=0.0975 Batch_id=1874 Accuracy=77.43: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1875/1875 [00:07<00:00, 236.31it/s]
Test set: Average loss: 0.1559, Accuracy: 57124/60000 (95.21%)
```

**Key Performance Metrics:**
- **Training Accuracy**: 77.43% (final batch)
- **Test Accuracy**: 95.21% (57,124/60,000 correct predictions)
- **Test Loss**: 0.1559
- **Training Speed**: 236.31 iterations/second on MPS

## ğŸ› ï¸ Project Structure

```
mnist-training-epo1/
â”œâ”€â”€ mnist_cnn_training.ipynb    # Main training notebook
â”œâ”€â”€ reports/                    # Generated HTML reports
â”‚   â”œâ”€â”€ CNN Model_MNIST_*.html
â”‚   â””â”€â”€ ...
â”œâ”€â”€ pyproject.toml             # Project dependencies
â”œâ”€â”€ requirements.txt           # Alternative dependency list
â”œâ”€â”€ uv.lock                   # UV lock file
â””â”€â”€ README.md                 # This file
```

## ğŸ”§ Dependencies

Core dependencies managed via `pyproject.toml`:
- **PyTorch** â‰¥ 2.8.0 (with MPS support)
- **TorchVision** â‰¥ 0.23.0
- **Matplotlib** â‰¥ 3.10.6
- **Pandas** â‰¥ 2.3.2
- **TQDM** â‰¥ 4.67.1
- **IPyKernel** â‰¥ 6.30.1

## ğŸ–¥ï¸ Device Support

The project automatically detects and uses the best available device:
- **MPS** (Apple Silicon GPU) - Primary choice for Mac users
- **CUDA** (NVIDIA GPU) - For NVIDIA GPU systems
- **CPU** - Fallback option

## ğŸ“ Usage Example

```python
# Initialize the model
model = Net().to(device)

# Set up training
optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1)
criterion = nn.CrossEntropyLoss()

# Train the model
for epoch in range(num_epochs):
    train(model, device, train_loader, optimizer, criterion)
    test(model, device, test_loader, criterion)
    scheduler.step()
```

## ğŸ“Š Data Augmentation

The training pipeline includes data augmentation:
- **Random Center Crop** (22Ã—22) with 10% probability
- **Random Rotation** (-15Â° to +15Â°)
- **Normalization** using MNIST statistics

## ğŸ¨ Visualization

Training reports include:
- Loss curves (training vs test)
- Accuracy progression
- Model architecture summary
- Performance metrics dashboard

## ğŸ“„ License

This project is licensed under the terms specified in the [LICENSE](LICENSE) file.

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Run the training notebook to generate reports
5. Submit a pull request

---

**Generated with â¤ï¸ using PyTorch and UV**